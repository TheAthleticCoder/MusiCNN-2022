# **Comparing Human Perception Of Song Similarity With ML Models**

This repository contains code for running `MusiCNN (git@github.com:jordipons/musicnn.git)` on `Google Colab`. 

-----

## **Objectives**

1. Identify and analyse the model's benefits and drawbacks in processing musical data, especially in comparison to human perception.

2. Examine any differences in how songs are perceived by musicians and non-musicians, particularly in terms of the timbre elements that they emphasize.

----

## **File Structure**

1. `dataset` The folder containing all the music samples which are in the form of pairs we used for our analysis. 
2. `project_scope.pdf` Slides which present the main idea behind our project and how we go about it.
3. `musicnn.ipynb` and `musicnn.py` Contains code for running `musicnn` library to generate cosine similarity between th song pairs.
4. `analysis_plots.ipynb` and `analysis_plots.py` For plotting correlations and other necessary graphs to compare how well the machine results and human results (taken from survey) are similar and find the reasons as to why they are dissimilar. 
5. `results.pdf` Slides displaying the experiment design and results generated and our analysis of the same.

-----


